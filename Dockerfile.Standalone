FROM nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04

ARG OOBABOOGA_COMMIT=cb26163a209d6272ed14da83782f71bae4681d75
ARG MODEL="TheBloke/Synthia-34B-v1.2-GPTQ"

ENV DEBIAN_FRONTEND=noninteractive \
    PIP_PREFER_BINARY=1 \
    PYTHONUNBUFFERED=1

SHELL ["/bin/bash", "-o", "pipefail", "-c"]

# Upgrade apt packages and install required dependencies
RUN apt update && \
    apt upgrade -y && \
    apt install -y \
      python3-dev \
      python3-pip \
      git \
      git-lfs && \
    apt autoremove -y && \
    rm -rf /var/lib/apt/lists/* && \
    apt clean -y

WORKDIR /workspace
RUN git clone https://github.com/oobabooga/text-generation-webui && \
    cd text-generation-webui && \
    git checkout ${OOBABOOGA_COMMIT} && \
    pip3 install --no-cache-dir torch==2.0.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 && \
    pip3 install --no-cache-dir xformers==0.0.22 && \
    pip3 install -r requirements.txt && \
    bash -c 'for req in extensions/*/requirements.txt ; do pip3 install -r "$req" ; done' && \
    deactivate

# Fetch the model
COPY download_model.py fetch_model.py /
RUN pip3 install huggingface_hub runpod && \
    /fetch_model.py ${MODEL} /workspace/text-generation-webui/models

# Docker container start script
COPY start_standalone.sh /start.sh
COPY rp_handler.py /
COPY schemas /schemas

# Start the container
RUN chmod +x /start.sh
CMD /start.sh
